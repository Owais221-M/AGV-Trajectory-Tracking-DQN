# Improved AGV Trajectory Tracking with DQN

This project implements an Autonomous Guided Vehicle (AGV) trajectory tracking system using a combination of:
- **Proportional-Integral (PI) controllers** for speed control.
- **Deep Q-Networks (DQN)** for reinforcement learning-based trajectory optimization.

The system is modeled using unicycle dynamics, with the objective of enabling the AGV to follow a circular trajectory while adjusting its wheel speeds.

---

## Features
- **Unicycle Dynamics Model**: Simulates the AGV's motion based on left and right wheel speeds.
- **Circular Reference Trajectory**: Generates a circular path for the AGV to follow.
- **DQN Agent**: Implements reinforcement learning for trajectory optimization using:
  - Experience replay.
  - Target network stabilization.
  - Epsilon-greedy action selection.
- **PI Controllers**: Handles speed control for the left and right wheels.
- **Visualization**: Plots the AGV's actual trajectory against the reference trajectory.

---

## Installation

1. Clone this repository:
    ```bash
    git clone https://github.com/Owais221-M/AGV-Trajectory-Tracking-DQN.git
    cd AGV-Trajectory-Tracking-DQN
    ```

2. Install the required dependencies:
    ```bash
    pip install numpy matplotlib scipy torch
    ```

---

## Usage

Run the main script to simulate AGV trajectory tracking:
```bash
AGV-Trajectory-Tracking-DQN.py
```

The script will:
- Generate a circular reference trajectory.
- Train the DQN agent to optimize trajectory tracking.
- Visualize the AGV's actual trajectory compared to the reference trajectory.

---

## Code Overview

### 1. AGV Dynamics Model (Unicycle Model)
- Defines the AGV's motion using wheel speeds and orientation.

### 2. Trajectory Planning
- Generates a circular reference trajectory using trigonometric functions.

### 3. DQN Agent
- A neural network-based reinforcement learning agent with features like experience replay and target network.

### 4. PI Controller
- Controls the left and right wheel speeds based on trajectory errors.

### 5. Simulation Loop
- Combines all components to:
  - Track the trajectory.
  - Train the DQN agent iteratively.

---

## Results
The AGV follows a circular trajectory as shown in the plot generated by the script. The DQN agent improves the trajectory tracking over time by learning from the AGV's errors and optimizing the control signals.

### **Conclusion**
The project demonstrates an innovative hybrid approach to AGV trajectory tracking by combining classical PI controllers with modern reinforcement learning through DQN. This method allows for improved adaptability and optimization in real-time trajectory tracking.

Key outcomes include:
- **Enhanced Performance**: The DQN agent effectively learns from trajectory errors and optimizes control signals over time.
- **Scalability**: The modular design supports extensions, such as handling more complex trajectories or integrating real-world constraints.
- **Visualization**: The AGV's ability to closely follow the reference trajectory is clearly illustrated through generated plots.

With further refinements, such as adaptive PI controllers, more complex learning architectures, and real-world simulations, this project has the potential to contribute significantly to autonomous navigation and robotics research. 


